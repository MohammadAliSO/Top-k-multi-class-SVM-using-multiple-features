# Top-k-multi-class-SVM-using-multiple-features
Implementation of the concepts expressed in the article (Top-k multi-class SVM using multiple features)

## Abstract  
This strategy relaxes the penalty for making an error in the top-k predictions, which can mitigate the challenge of class ambiguity to some extent. To fuse multiple features effectively, we introduce an adaptive weight for each view and exploit an efficient alternating optimization algorithm to learn the optimal classifiers and their corresponding weights jointly

![image](https://github.com/MohammadAliSO/Top-k-multi-class-SVM-using-multiple-features/assets/48887675/1c815dae-a693-46d9-80e4-de84762dee8b)
